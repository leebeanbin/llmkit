"""
RAG Debug Utils - RAG íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹… ë° ê²€ì¦ ë„êµ¬
ì¤‘ê°„ ê³¼ì •ì„ í™•ì¸í•˜ê³  ë¬¸ì œë¥¼ ì°¾ëŠ” ë° ë„ì›€
"""
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False
    # numpy ëŒ€ì²´ í•¨ìˆ˜ë“¤
    class np:
        @staticmethod
        def array(x):
            return x

        @staticmethod
        def dot(a, b):
            return sum(x * y for x, y in zip(a, b))

        @staticmethod
        def linalg_norm(x):
            return sum(v ** 2 for v in x) ** 0.5

        class linalg:
            @staticmethod
            def norm(x):
                return sum(v ** 2 for v in x) ** 0.5

from .document_loaders import Document


@dataclass
class EmbeddingInfo:
    """ì„ë² ë”© ì •ë³´"""
    text: str
    vector: List[float]
    dimension: int
    norm: float  # ë²¡í„° í¬ê¸°
    preview: List[float]  # ì• 10ê°œ ê°’


@dataclass
class SimilarityInfo:
    """ìœ ì‚¬ë„ ì •ë³´"""
    text1: str
    text2: str
    cosine_similarity: float
    euclidean_distance: float
    interpretation: str  # í•´ì„


class RAGDebugger:
    """
    RAG íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹… ë„êµ¬

    Example:
        debugger = RAGDebugger()

        # ì„ë² ë”© í™•ì¸
        debugger.inspect_embedding(text, vector)

        # ìœ ì‚¬ë„ í™•ì¸
        debugger.compare_texts(text1, text2, embedding_function)

        # Vector Store í™•ì¸
        debugger.inspect_vector_store(store, sample_queries)
    """

    def __init__(self, verbose: bool = True):
        """
        Args:
            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
        """
        self.verbose = verbose

    def _print(self, *args, **kwargs):
        """Verbose ëª¨ë“œì¼ ë•Œë§Œ ì¶œë ¥"""
        if self.verbose:
            print(*args, **kwargs)

    # ==================== ì„ë² ë”© ê²€ì¦ ====================

    def inspect_embedding(
        self,
        text: str,
        vector: List[float],
        show_preview: int = 10
    ) -> EmbeddingInfo:
        """
        ë‹¨ì¼ ì„ë² ë”© ê²€ì‚¬

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            vector: ì„ë² ë”© ë²¡í„°
            show_preview: ë¯¸ë¦¬ë³´ê¸° ê°œìˆ˜

        Returns:
            EmbeddingInfo
        """
        dimension = len(vector)
        norm = float(np.linalg.norm(vector))
        preview = vector[:show_preview]

        info = EmbeddingInfo(
            text=text,
            vector=vector,
            dimension=dimension,
            norm=norm,
            preview=preview
        )

        self._print(f"\n{'='*60}")
        self._print("ğŸ“Š Embedding ì •ë³´")
        self._print(f"{'='*60}")
        self._print(f"í…ìŠ¤íŠ¸: {text[:100]}...")
        self._print(f"ì°¨ì›: {dimension}")
        self._print(f"ë²¡í„° í¬ê¸° (norm): {norm:.4f}")
        self._print(f"ë¯¸ë¦¬ë³´ê¸° ({show_preview}ê°œ):")
        self._print(f"  {preview}")
        self._print(f"{'='*60}\n")

        return info

    def compare_embeddings(
        self,
        embeddings: List[Tuple[str, List[float]]]
    ) -> None:
        """
        ì—¬ëŸ¬ ì„ë² ë”© ë¹„êµ

        Args:
            embeddings: [(text, vector), ...] ë¦¬ìŠ¤íŠ¸

        Example:
            debugger.compare_embeddings([
                ("ê°•ì•„ì§€", vec1),
                ("ê°œ", vec2),
                ("ìë™ì°¨", vec3)
            ])
        """
        self._print(f"\n{'='*60}")
        self._print("ğŸ“Š Embeddings ë¹„êµ")
        self._print(f"{'='*60}")

        # ê° ì„ë² ë”© ê¸°ë³¸ ì •ë³´
        for text, vector in embeddings:
            norm = float(np.linalg.norm(vector))
            self._print(f"\n{text}:")
            self._print(f"  ì°¨ì›: {len(vector)}")
            self._print(f"  Norm: {norm:.4f}")
            self._print(f"  ì• 5ê°œ: {vector[:5]}")

        # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
        self._print(f"\n{'='*60}")
        self._print("ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ (Cosine Similarity):")
        self._print(f"{'='*60}")

        texts = [t for t, _ in embeddings]
        vectors = [v for _, v in embeddings]

        # í—¤ë”
        header = f"{'':15}"
        for text in texts:
            header += f"{text[:12]:>15}"
        self._print(header)
        self._print("-" * (15 + 15 * len(texts)))

        # ê° í–‰
        for i, text1 in enumerate(texts):
            row = f"{text1[:12]:15}"
            for j, text2 in enumerate(texts):
                sim = self._cosine_similarity(vectors[i], vectors[j])
                row += f"{sim:>15.3f}"
            self._print(row)

        self._print(f"{'='*60}\n")

    # ==================== ìœ ì‚¬ë„ ê³„ì‚° ====================

    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        a_arr = np.array(a)
        b_arr = np.array(b)
        return float(np.dot(a_arr, b_arr) / (np.linalg.norm(a_arr) * np.linalg.norm(b_arr)))

    def _euclidean_distance(self, a: List[float], b: List[float]) -> float:
        """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
        if HAS_NUMPY:
            import numpy as real_np
            a_arr = real_np.array(a)
            b_arr = real_np.array(b)
            return float(real_np.linalg.norm(a_arr - b_arr))
        else:
            # numpy ì—†ì´ ê³„ì‚°
            return sum((x - y) ** 2 for x, y in zip(a, b)) ** 0.5

    def _interpret_similarity(self, cosine_sim: float) -> str:
        """ìœ ì‚¬ë„ í•´ì„"""
        if cosine_sim >= 0.9:
            return "ë§¤ìš° ìœ ì‚¬ (ê±°ì˜ ê°™ì€ ì˜ë¯¸)"
        elif cosine_sim >= 0.7:
            return "ìœ ì‚¬ (ê´€ë ¨ìˆëŠ” ë‚´ìš©)"
        elif cosine_sim >= 0.5:
            return "ì–´ëŠì •ë„ ê´€ë ¨ (ì•½í•œ ì—°ê´€ì„±)"
        elif cosine_sim >= 0.3:
            return "ì•½ê°„ ê´€ë ¨ (ê±°ì˜ ë¬´ê´€)"
        else:
            return "ë¬´ê´€ (ì „í˜€ ë‹¤ë¥¸ ì˜ë¯¸)"

    def compare_texts(
        self,
        text1: str,
        text2: str,
        embedding_function
    ) -> SimilarityInfo:
        """
        ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚°

        Args:
            text1: ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸
            text2: ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸
            embedding_function: ì„ë² ë”© í•¨ìˆ˜

        Returns:
            SimilarityInfo
        """
        # ì„ë² ë”© ìƒì„±
        vectors = embedding_function([text1, text2])
        vec1, vec2 = vectors[0], vectors[1]

        # ìœ ì‚¬ë„ ê³„ì‚°
        cosine_sim = self._cosine_similarity(vec1, vec2)
        euclidean_dist = self._euclidean_distance(vec1, vec2)
        interpretation = self._interpret_similarity(cosine_sim)

        info = SimilarityInfo(
            text1=text1,
            text2=text2,
            cosine_similarity=cosine_sim,
            euclidean_distance=euclidean_dist,
            interpretation=interpretation
        )

        self._print(f"\n{'='*60}")
        self._print("ğŸ“Š í…ìŠ¤íŠ¸ ìœ ì‚¬ë„")
        self._print(f"{'='*60}")
        self._print(f"í…ìŠ¤íŠ¸ 1: {text1[:50]}...")
        self._print(f"í…ìŠ¤íŠ¸ 2: {text2[:50]}...")
        self._print(f"\nì½”ì‚¬ì¸ ìœ ì‚¬ë„: {cosine_sim:.4f}")
        self._print(f"ìœ í´ë¦¬ë“œ ê±°ë¦¬: {euclidean_dist:.4f}")
        self._print(f"í•´ì„: {interpretation}")
        self._print(f"{'='*60}\n")

        return info

    # ==================== ì²­í¬ ê²€ì¦ ====================

    def inspect_chunks(
        self,
        chunks: List[Document],
        show_samples: int = 3
    ) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ì²­í¬ ê²€ì‚¬

        Args:
            chunks: ì²­í¬ ë¦¬ìŠ¤íŠ¸
            show_samples: ìƒ˜í”Œ ê°œìˆ˜

        Returns:
            ì²­í¬ í†µê³„
        """
        if not chunks:
            self._print("âš ï¸  ì²­í¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            return {}

        # í†µê³„
        total_chunks = len(chunks)
        chunk_lengths = [len(chunk.content) for chunk in chunks]
        avg_length = sum(chunk_lengths) / len(chunk_lengths)
        min_length = min(chunk_lengths)
        max_length = max(chunk_lengths)

        stats = {
            "total_chunks": total_chunks,
            "avg_length": avg_length,
            "min_length": min_length,
            "max_length": max_length,
            "chunk_lengths": chunk_lengths
        }

        self._print(f"\n{'='*60}")
        self._print("ğŸ“„ ì²­í¬ ì •ë³´")
        self._print(f"{'='*60}")
        self._print(f"ì´ ì²­í¬ ìˆ˜: {total_chunks}")
        self._print(f"í‰ê·  ê¸¸ì´: {avg_length:.1f} ë¬¸ì")
        self._print(f"ìµœì†Œ ê¸¸ì´: {min_length} ë¬¸ì")
        self._print(f"ìµœëŒ€ ê¸¸ì´: {max_length} ë¬¸ì")

        # ìƒ˜í”Œ ì¶œë ¥
        self._print(f"\nìƒ˜í”Œ ì²­í¬ (ì²˜ìŒ {show_samples}ê°œ):")
        for i, chunk in enumerate(chunks[:show_samples], 1):
            self._print(f"\n[Chunk {i}] ({len(chunk.content)} ë¬¸ì)")
            self._print(f"  ë‚´ìš©: {chunk.content[:100]}...")
            if chunk.metadata:
                self._print(f"  ë©”íƒ€: {chunk.metadata}")

        self._print(f"{'='*60}\n")

        return stats

    # ==================== Vector Store ê²€ì¦ ====================

    def inspect_vector_store(
        self,
        store,
        sample_queries: List[str],
        k: int = 3
    ) -> Dict[str, Any]:
        """
        Vector Store ê²€ì‚¬

        Args:
            store: VectorStore ì¸ìŠ¤í„´ìŠ¤
            sample_queries: í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼
        """
        self._print(f"\n{'='*60}")
        self._print("ğŸ” Vector Store ê²€ì‚¬")
        self._print(f"{'='*60}")

        results = {}

        for query in sample_queries:
            self._print(f"\nì¿¼ë¦¬: \"{query}\"")
            self._print("-" * 60)

            try:
                search_results = store.similarity_search(query, k=k)

                if not search_results:
                    self._print("  âš ï¸  ê²°ê³¼ ì—†ìŒ")
                    results[query] = []
                    continue

                results[query] = search_results

                for i, result in enumerate(search_results, 1):
                    score = result.score
                    content = result.document.content
                    metadata = result.document.metadata

                    self._print(f"\n  [{i}] Score: {score:.4f}")
                    self._print(f"      Content: {content[:100]}...")
                    if metadata:
                        self._print(f"      Metadata: {metadata}")

                    # ì ìˆ˜ í•´ì„
                    interpretation = self._interpret_similarity(score)
                    self._print(f"      í•´ì„: {interpretation}")

            except Exception as e:
                self._print(f"  âŒ ì—ëŸ¬: {e}")
                results[query] = None

        self._print(f"\n{'='*60}\n")

        return results

    # ==================== ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ====================

    def validate_rag_pipeline(
        self,
        documents: List[Document],
        chunks: List[Document],
        embedding_function,
        store,
        test_queries: List[str]
    ) -> Dict[str, Any]:
        """
        ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ê²€ì¦

        Args:
            documents: ì›ë³¸ ë¬¸ì„œ
            chunks: ë¶„í• ëœ ì²­í¬
            embedding_function: ì„ë² ë”© í•¨ìˆ˜
            store: VectorStore
            test_queries: í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬

        Returns:
            ì „ì²´ ê²€ì¦ ê²°ê³¼
        """
        self._print(f"\n{'#'*60}")
        self._print("# RAG íŒŒì´í”„ë¼ì¸ ì „ì²´ ê²€ì¦")
        self._print(f"{'#'*60}\n")

        report = {}

        # 1. ë¬¸ì„œ í™•ì¸
        self._print("1ï¸âƒ£  ì›ë³¸ ë¬¸ì„œ í™•ì¸")
        report["documents"] = {
            "count": len(documents),
            "total_length": sum(len(doc.content) for doc in documents)
        }
        self._print(f"   âœ“ {len(documents)}ê°œ ë¬¸ì„œ, ì´ {report['documents']['total_length']} ë¬¸ì\n")

        # 2. ì²­í¬ í™•ì¸
        self._print("2ï¸âƒ£  ì²­í¬ í™•ì¸")
        chunk_stats = self.inspect_chunks(chunks, show_samples=2)
        report["chunks"] = chunk_stats

        # 3. ì„ë² ë”© í…ŒìŠ¤íŠ¸
        self._print("3ï¸âƒ£  ì„ë² ë”© í…ŒìŠ¤íŠ¸")
        test_text = chunks[0].content[:100] if chunks else "Test"
        test_vector = embedding_function([test_text])[0]
        self.inspect_embedding(test_text, test_vector, show_preview=5)
        report["embedding_dim"] = len(test_vector)

        # 4. Vector Store í…ŒìŠ¤íŠ¸
        self._print("4ï¸âƒ£  Vector Store í…ŒìŠ¤íŠ¸")
        search_results = self.inspect_vector_store(store, test_queries, k=3)
        report["search_results"] = search_results

        # 5. ì¢…í•© í‰ê°€
        self._print(f"\n{'='*60}")
        self._print("ğŸ“Š ì¢…í•© í‰ê°€")
        self._print(f"{'='*60}")

        issues = []

        # ì²­í¬ í¬ê¸° í™•ì¸
        if chunk_stats.get("avg_length", 0) < 50:
            issues.append("âš ï¸  ì²­í¬ê°€ ë„ˆë¬´ ì‘ìŒ (í‰ê·  < 50)")
        elif chunk_stats.get("avg_length", 0) > 2000:
            issues.append("âš ï¸  ì²­í¬ê°€ ë„ˆë¬´ í¼ (í‰ê·  > 2000)")

        # ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        empty_results = sum(1 for r in search_results.values() if not r)
        if empty_results > 0:
            issues.append(f"âš ï¸  {empty_results}ê°œ ì¿¼ë¦¬ì—ì„œ ê²°ê³¼ ì—†ìŒ")

        # ë‚®ì€ ì ìˆ˜ í™•ì¸
        low_scores = []
        for query, results in search_results.items():
            if results and results[0].score < 0.5:
                low_scores.append((query, results[0].score))

        if low_scores:
            issues.append(f"âš ï¸  {len(low_scores)}ê°œ ì¿¼ë¦¬ì—ì„œ ë‚®ì€ ì ìˆ˜ (< 0.5)")

        if not issues:
            self._print("âœ… ë¬¸ì œ ì—†ìŒ - íŒŒì´í”„ë¼ì¸ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
        else:
            self._print("ë°œê²¬ëœ ë¬¸ì œ:")
            for issue in issues:
                self._print(f"  {issue}")

        self._print(f"{'='*60}\n")

        report["issues"] = issues

        return report


# ==================== í¸ì˜ í•¨ìˆ˜ ====================

def inspect_embedding(
    text: str,
    embedding_function,
    show_preview: int = 10
) -> EmbeddingInfo:
    """
    ì„ë² ë”© ê²€ì‚¬ (ê°„ë‹¨í•œ ë²„ì „)

    Example:
        from llmkit import Embedding, inspect_embedding

        embed_func = Embedding.openai().embed_sync
        info = inspect_embedding("Hello world", embed_func)
    """
    vector = embedding_function([text])[0]
    debugger = RAGDebugger(verbose=True)
    return debugger.inspect_embedding(text, vector, show_preview)


def compare_texts(
    text1: str,
    text2: str,
    embedding_function
) -> SimilarityInfo:
    """
    ë‘ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¹„êµ (ê°„ë‹¨í•œ ë²„ì „)

    Example:
        from llmkit import Embedding, compare_texts

        embed_func = Embedding.openai().embed_sync
        info = compare_texts("ê°•ì•„ì§€", "ê°œ", embed_func)
    """
    debugger = RAGDebugger(verbose=True)
    return debugger.compare_texts(text1, text2, embedding_function)


def validate_pipeline(
    documents: List[Document],
    chunks: List[Document],
    embedding_function,
    store,
    test_queries: List[str] = None
) -> Dict[str, Any]:
    """
    ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ê²€ì¦ (ê°„ë‹¨í•œ ë²„ì „)

    Example:
        from llmkit import validate_pipeline

        report = validate_pipeline(
            documents=docs,
            chunks=chunks,
            embedding_function=embed_func,
            store=store,
            test_queries=["What is AI?", "How does ML work?"]
        )
    """
    if test_queries is None:
        # ê¸°ë³¸ ì¿¼ë¦¬
        test_queries = [chunks[0].content[:50]] if chunks else ["test"]

    debugger = RAGDebugger(verbose=True)
    return debugger.validate_rag_pipeline(
        documents, chunks, embedding_function, store, test_queries
    )


# ==================== ì‹œê°í™” ìœ í‹¸ë¦¬í‹° ====================

def visualize_embeddings_2d(
    texts: List[str],
    embedding_function,
    save_path: Optional[str] = None
):
    """
    ì„ë² ë”©ì„ 2Dë¡œ ì‹œê°í™”

    Args:
        texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        embedding_function: ì„ë² ë”© í•¨ìˆ˜
        save_path: ì €ì¥ ê²½ë¡œ (ì„ íƒ)

    Example:
        from llmkit import Embedding, visualize_embeddings_2d

        texts = ["ê°•ì•„ì§€", "ê°œ", "ê³ ì–‘ì´", "ìë™ì°¨", "ë¹„í–‰ê¸°"]
        embed_func = Embedding.openai().embed_sync
        visualize_embeddings_2d(texts, embed_func)
    """
    try:
        import matplotlib.pyplot as plt
        from sklearn.manifold import TSNE
    except ImportError:
        print("âš ï¸  sklearnê³¼ matplotlib í•„ìš”:")
        print("   pip install scikit-learn matplotlib")
        return

    # ì„ë² ë”© ìƒì„±
    vectors = embedding_function(texts)
    vectors_array = np.array(vectors)

    # 2Dë¡œ ì¶•ì†Œ
    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(texts)-1))
    vectors_2d = tsne.fit_transform(vectors_array)

    # ì‹œê°í™”
    plt.figure(figsize=(12, 8))
    plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], s=200, alpha=0.6)

    for i, text in enumerate(texts):
        x, y = vectors_2d[i]
        plt.annotate(
            text,
            (x, y),
            fontsize=12,
            ha='center',
            va='bottom'
        )

    plt.title("Embeddings ì‹œê°í™” (2D íˆ¬ì˜)", fontsize=16)
    plt.xlabel("Dimension 1")
    plt.ylabel("Dimension 2")
    plt.grid(True, alpha=0.3)

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}")

    plt.show()


def similarity_heatmap(
    texts: List[str],
    embedding_function,
    save_path: Optional[str] = None
):
    """
    ìœ ì‚¬ë„ íˆíŠ¸ë§µ ìƒì„±

    Args:
        texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        embedding_function: ì„ë² ë”© í•¨ìˆ˜
        save_path: ì €ì¥ ê²½ë¡œ (ì„ íƒ)

    Example:
        from llmkit import Embedding, similarity_heatmap

        texts = ["AI", "ML", "DL", "NLP", "CV"]
        embed_func = Embedding.openai().embed_sync
        similarity_heatmap(texts, embed_func)
    """
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
    except ImportError:
        print("âš ï¸  matplotlibì™€ seaborn í•„ìš”:")
        print("   pip install matplotlib seaborn")
        return

    # ì„ë² ë”© ìƒì„±
    vectors = embedding_function(texts)

    # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
    n = len(vectors)
    similarity_matrix = np.zeros((n, n))

    for i in range(n):
        for j in range(n):
            a = np.array(vectors[i])
            b = np.array(vectors[j])
            similarity_matrix[i, j] = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

    # íˆíŠ¸ë§µ
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        similarity_matrix,
        annot=True,
        fmt='.3f',
        xticklabels=texts,
        yticklabels=texts,
        cmap='RdYlGn',
        vmin=0,
        vmax=1,
        square=True
    )

    plt.title("Cosine Similarity Heatmap", fontsize=16)
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ ì €ì¥: {save_path}")

    plt.show()
