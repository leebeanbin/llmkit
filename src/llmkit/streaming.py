"""
Streaming Helpers
ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ í—¬í¼
"""
import asyncio
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, AsyncIterator, Callable, Optional

from rich.console import Console
from rich.live import Live
from rich.markdown import Markdown
from rich.panel import Panel
from rich.text import Text

from .utils.logger import get_logger

logger = get_logger(__name__)

console = Console()


@dataclass
class StreamStats:
    """ìŠ¤íŠ¸ë¦¬ë° í†µê³„"""
    total_tokens: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    chunks: int = 0

    @property
    def duration(self) -> float:
        """ì†Œìš” ì‹œê°„ (ì´ˆ)"""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return 0.0

    @property
    def tokens_per_second(self) -> float:
        """ì´ˆë‹¹ í† í° ìˆ˜"""
        if self.duration > 0:
            return self.total_tokens / self.duration
        return 0.0


@dataclass
class StreamResponse:
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ê²°ê³¼"""
    content: str
    stats: StreamStats
    metadata: dict = field(default_factory=dict)


async def stream_response(
    stream: AsyncIterator[str],
    return_output: bool = True,
    display: bool = True,
    use_rich: bool = True,
    markdown: bool = False,
    show_stats: bool = False,
    panel_title: Optional[str] = None,
    on_chunk: Optional[Callable[[str], Any]] = None
) -> Optional[StreamResponse]:
    """
    ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶œë ¥ í—¬í¼

    ì°¸ê³ : LangChainê³¼ TeddyNoteì˜ stream_responseì—ì„œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.
    llmkitì˜ ê°œì„ ëœ ê¸°ëŠ¥:
    - Rich ê¸°ë°˜ ì•„ë¦„ë‹¤ìš´ ì¶œë ¥
    - ë§ˆí¬ë‹¤ìš´ ë Œë”ë§
    - í†µê³„ ì •ë³´ (í† í° ìˆ˜, ì†ë„)
    - ì»¤ìŠ¤í…€ ì½œë°±
    - Panel ë˜í•‘

    Args:
        stream: AsyncIterator[str] - ìŠ¤íŠ¸ë¦¼ ì†ŒìŠ¤
        return_output: ì¶œë ¥ ë‚´ìš© ë°˜í™˜ ì—¬ë¶€
        display: í™”ë©´ ì¶œë ¥ ì—¬ë¶€
        use_rich: rich ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ì—¬ë¶€
        markdown: ë§ˆí¬ë‹¤ìš´ ë Œë”ë§ ì—¬ë¶€
        show_stats: í†µê³„ ì •ë³´ í‘œì‹œ
        panel_title: Panel ì œëª©
        on_chunk: ì²­í¬ë§ˆë‹¤ í˜¸ì¶œí•  ì½œë°±

    Returns:
        StreamResponse | None: ì‘ë‹µ ê²°ê³¼ (return_output=Trueì¸ ê²½ìš°)

    Example:
        ```python
        from llmkit import Client, stream_response

        client = Client(model="gpt-4o-mini")
        stream = client.stream_chat(messages, temperature=0.7)

        # ê¸°ë³¸ ì¶œë ¥
        await stream_response(stream)

        # ë§ˆí¬ë‹¤ìš´ + í†µê³„
        result = await stream_response(
            stream,
            markdown=True,
            show_stats=True,
            panel_title="GPT-4o-mini"
        )
        print(f"Tokens: {result.stats.total_tokens}")
        print(f"Speed: {result.stats.tokens_per_second:.2f} tok/s")
        ```
    """
    stats = StreamStats(start_time=datetime.now())
    collected = []

    try:
        if display and use_rich and panel_title:
            # Rich Panel + Live ì—…ë°ì´íŠ¸
            with Live(console=console, refresh_per_second=10) as live:
                current_text = ""
                async for chunk in stream:
                    current_text += chunk
                    collected.append(chunk)
                    stats.chunks += 1

                    if on_chunk:
                        on_chunk(chunk)

                    # Live ì—…ë°ì´íŠ¸
                    if markdown:
                        content = Markdown(current_text)
                    else:
                        content = Text(current_text)

                    live.update(Panel(
                        content,
                        title=f"[bold cyan]{panel_title}[/bold cyan]",
                        border_style="cyan"
                    ))

        elif display and use_rich:
            # Rich ì¶œë ¥ (Panel ì—†ìŒ)
            current_text = ""
            async for chunk in stream:
                current_text += chunk
                collected.append(chunk)
                stats.chunks += 1

                if on_chunk:
                    on_chunk(chunk)

                # ì ì§„ì  ì¶œë ¥
                console.print(chunk, end="", markup=False)

            console.print()  # ì¤„ë°”ê¿ˆ

        elif display:
            # ì¼ë°˜ print ì¶œë ¥
            async for chunk in stream:
                collected.append(chunk)
                stats.chunks += 1

                if on_chunk:
                    on_chunk(chunk)

                print(chunk, end="", flush=True)

            print()  # ì¤„ë°”ê¿ˆ

        else:
            # ì¶œë ¥ ì—†ìŒ, ìˆ˜ì§‘ë§Œ
            async for chunk in stream:
                collected.append(chunk)
                stats.chunks += 1

                if on_chunk:
                    on_chunk(chunk)

        stats.end_time = datetime.now()
        final_content = "".join(collected)

        # í† í° ìˆ˜ ì¶”ì • (ê³µë°± ê¸°ì¤€)
        stats.total_tokens = len(final_content.split())

        # í†µê³„ í‘œì‹œ
        if show_stats and display:
            _display_stats(stats)

        if return_output:
            return StreamResponse(
                content=final_content,
                stats=stats,
                metadata={}
            )

        return None

    except Exception as e:
        logger.error(f"Stream error: {e}")
        raise


def _display_stats(stats: StreamStats):
    """í†µê³„ ì •ë³´ í‘œì‹œ"""
    stats_panel = Panel(
        f"""[bold cyan]Duration:[/bold cyan] {stats.duration:.2f}s
[bold cyan]Tokens:[/bold cyan] {stats.total_tokens}
[bold cyan]Speed:[/bold cyan] {stats.tokens_per_second:.2f} tok/s
[bold cyan]Chunks:[/bold cyan] {stats.chunks}""",
        title="[bold yellow]ğŸ“Š Statistics[/bold yellow]",
        border_style="yellow",
        expand=False
    )
    console.print()
    console.print(stats_panel)


async def stream_print(
    stream: AsyncIterator[str],
    markdown: bool = False,
    panel_title: Optional[str] = None
) -> str:
    """
    ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ (ì§§ì€ ë²„ì „)

    Example:
        ```python
        content = await stream_print(stream, markdown=True)
        ```
    """
    result = await stream_response(
        stream,
        return_output=True,
        display=True,
        use_rich=True,
        markdown=markdown,
        panel_title=panel_title
    )
    return result.content if result else ""


async def stream_collect(stream: AsyncIterator[str]) -> str:
    """
    ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì§‘ë§Œ (ì¶œë ¥ ì—†ìŒ)

    Example:
        ```python
        content = await stream_collect(stream)
        ```
    """
    result = await stream_response(
        stream,
        return_output=True,
        display=False
    )
    return result.content if result else ""


class StreamBuffer:
    """
    ìŠ¤íŠ¸ë¦¬ë° ë²„í¼
    ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ì„ ë™ì‹œì— ì²˜ë¦¬
    """

    def __init__(self):
        self.buffers = {}
        self._lock = asyncio.Lock()

    async def add_chunk(self, stream_id: str, chunk: str):
        """ì²­í¬ ì¶”ê°€"""
        async with self._lock:
            if stream_id not in self.buffers:
                self.buffers[stream_id] = []
            self.buffers[stream_id].append(chunk)

    def get_content(self, stream_id: str) -> str:
        """ì „ì²´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        return "".join(self.buffers.get(stream_id, []))

    def clear(self, stream_id: str):
        """ë²„í¼ ì´ˆê¸°í™”"""
        if stream_id in self.buffers:
            del self.buffers[stream_id]

    def get_all(self) -> dict:
        """ëª¨ë“  ë²„í¼ ë‚´ìš©"""
        return {
            stream_id: "".join(chunks)
            for stream_id, chunks in self.buffers.items()
        }


# í¸ì˜ í•¨ìˆ˜
async def pretty_stream(
    stream: AsyncIterator[str],
    title: str = "Response"
) -> StreamResponse:
    """
    ì˜ˆìœ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ (ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™”)

    Example:
        ```python
        from llmkit import Client
        from llmkit.streaming import pretty_stream

        client = Client(model="gpt-4o-mini")
        stream = client.stream_chat(messages)
        result = await pretty_stream(stream, title="GPT-4o-mini")
        ```
    """
    return await stream_response(
        stream,
        return_output=True,
        display=True,
        use_rich=True,
        markdown=True,
        show_stats=True,
        panel_title=title
    )
