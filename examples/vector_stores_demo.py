"""
Vector Stores Demo - Fluent API
beanllm ë°©ì‹: ì‰½ê³  ê°•ë ¥í•œ ë²¡í„° ìŠ¤í† ì–´
"""
import asyncio
from beanllm import (
    VectorStore,
    VectorStoreBuilder,
    create_vector_store,
    from_documents,
    DocumentLoader,
    TextSplitter,
    Embedding,
    Document
)


def demo_basic_usage():
    """ê¸°ë³¸ ì‚¬ìš©ë²•"""
    print("\n" + "="*60)
    print("ğŸ“¦ ê¸°ë³¸ ì‚¬ìš©ë²•")
    print("="*60)

    # ì„ë² ë”© í•¨ìˆ˜ ì¤€ë¹„
    try:
        emb = Embedding(model="text-embedding-3-small")
        embed_func = emb.embed_sync
        print("\nâœ“ Using OpenAI embeddings")
    except:
        # API í‚¤ ì—†ìœ¼ë©´ ë”ë¯¸
        import random
        embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]
        print("\nâš ï¸  Using dummy embeddings (no API key)")

    # 1. ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•
    print("\n1. ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•:")
    try:
        store = VectorStore.chroma(embedding_function=embed_func)

        docs = [
            Document(content="AI is transforming the world"),
            Document(content="Machine learning learns from data"),
            Document(content="Deep learning uses neural networks")
        ]

        store.add_documents(docs)
        results = store.similarity_search("artificial intelligence", k=2)

        print(f"   âœ“ Found {len(results)} documents")
        for i, result in enumerate(results[:2], 1):
            print(f"   {i}. {result.document.content[:50]}... (score: {result.score:.3f})")

    except Exception as e:
        print(f"   âš ï¸  {e}")

    print("\nâœ“ ê¸°ë³¸ ì‚¬ìš©ë²• ì™„ë£Œ!")


def demo_factory_methods():
    """íŒ©í† ë¦¬ ë©”ì„œë“œ"""
    print("\n" + "="*60)
    print("ğŸ­ íŒ©í† ë¦¬ ë©”ì„œë“œ")
    print("="*60)

    import random
    embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

    # Chroma
    print("\n1. Chroma (ë¡œì»¬, ì‰¬ì›€):")
    try:
        store = VectorStore.chroma(
            collection_name="demo_chroma",
            embedding_function=embed_func
        )
        print("   âœ“ Chroma store created")
    except Exception as e:
        print(f"   âš ï¸  {e}")

    # FAISS
    print("\n2. FAISS (ë¡œì»¬, ë¹ ë¦„):")
    try:
        store = VectorStore.faiss(
            dimension=384,
            embedding_function=embed_func
        )
        print("   âœ“ FAISS store created")
    except Exception as e:
        print(f"   âš ï¸  {e}")

    print("\nâœ“ íŒ©í† ë¦¬ ë©”ì„œë“œ ì™„ë£Œ!")


def demo_fluent_api():
    """Fluent API"""
    print("\n" + "="*60)
    print("âœ¨ Fluent API (Builder Pattern)")
    print("="*60)

    import random
    embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

    print("\n1. Builder íŒ¨í„´:")
    try:
        store = (VectorStoreBuilder()
            .use_chroma()
            .with_embedding(embed_func)
            .with_collection("fluent_demo")
            .build())

        print("   âœ“ Store built with fluent API")

        # ì‚¬ìš©
        docs = [Document(content="Fluent API is elegant")]
        store.add_documents(docs)
        results = store.similarity_search("elegant", k=1)

        print(f"   âœ“ Found: {results[0].document.content}")

    except Exception as e:
        print(f"   âš ï¸  {e}")

    print("\nâœ“ Fluent API ì™„ë£Œ!")


def demo_convenience_functions():
    """í¸ì˜ í•¨ìˆ˜"""
    print("\n" + "="*60)
    print("âš¡ í¸ì˜ í•¨ìˆ˜")
    print("="*60)

    import random
    embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

    # create_vector_store()
    print("\n1. create_vector_store():")
    try:
        store = create_vector_store(
            provider="chroma",
            embedding_function=embed_func,
            collection_name="convenience_demo"
        )
        print("   âœ“ Store created")
    except Exception as e:
        print(f"   âš ï¸  {e}")

    # from_documents()
    print("\n2. from_documents() - ê°€ì¥ í¸ë¦¬!")
    try:
        docs = [
            Document(content="Quick document 1"),
            Document(content="Quick document 2"),
            Document(content="Quick document 3")
        ]

        store = from_documents(
            docs,
            embedding_function=embed_func,
            provider="chroma",
            collection_name="from_docs_demo"
        )

        print(f"   âœ“ Store created with {len(docs)} documents")

        results = store.similarity_search("quick", k=2)
        print(f"   âœ“ Search: {len(results)} results")

    except Exception as e:
        print(f"   âš ï¸  {e}")

    print("\nâœ“ í¸ì˜ í•¨ìˆ˜ ì™„ë£Œ!")


async def demo_full_rag_pipeline():
    """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸"""
    print("\n" + "="*60)
    print("ğŸš€ ì „ì²´ RAG íŒŒì´í”„ë¼ì¸")
    print("="*60)

    from pathlib import Path

    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    test_file = Path("rag_demo.txt")
    test_file.write_text("""
Artificial Intelligence is revolutionizing technology.
Machine learning algorithms learn patterns from data.
Deep learning uses multi-layer neural networks.
Natural language processing understands human language.
Computer vision enables machines to see and interpret images.
    """.strip(), encoding="utf-8")

    try:
        # 1. ë¬¸ì„œ ë¡œë”©
        print("\n1. ë¬¸ì„œ ë¡œë”©:")
        docs = DocumentLoader.load(test_file)
        print(f"   âœ“ Loaded {len(docs)} document(s)")

        # 2. í…ìŠ¤íŠ¸ ë¶„í• 
        print("\n2. í…ìŠ¤íŠ¸ ë¶„í• :")
        chunks = TextSplitter.split(docs, chunk_size=100)
        print(f"   âœ“ Split into {len(chunks)} chunks")

        # 3. ì„ë² ë”© ì¤€ë¹„
        print("\n3. ì„ë² ë”© ì¤€ë¹„:")
        try:
            from beanllm import embed_sync
            embed_func = lambda texts: embed_sync(texts)
            print("   âœ“ Using OpenAI embeddings")
        except:
            import random
            embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]
            print("   âš ï¸  Using dummy embeddings")

        # 4. Vector Store ìƒì„± ë° ë¬¸ì„œ ì¶”ê°€
        print("\n4. Vector Store ìƒì„±:")
        store = from_documents(
            chunks,
            embedding_function=embed_func,
            provider="chroma",
            collection_name="rag_pipeline"
        )
        print(f"   âœ“ Created vector store with {len(chunks)} chunks")

        # 5. ê²€ìƒ‰
        print("\n5. ì§ˆì˜ ê²€ìƒ‰:")
        query = "What is machine learning?"
        results = store.similarity_search(query, k=3)

        print(f"   Query: \"{query}\"")
        print(f"   Found {len(results)} relevant chunks:")
        for i, result in enumerate(results, 1):
            print(f"   {i}. {result.document.content[:60]}...")
            print(f"      Score: {result.score:.3f}")

        print("\nâœ“ ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")

    except Exception as e:
        print(f"   âš ï¸  {e}")
        import traceback
        traceback.print_exc()

    finally:
        # ì •ë¦¬
        if test_file.exists():
            test_file.unlink()


async def demo_async_operations():
    """ë¹„ë™ê¸° ì‘ì—…"""
    print("\n" + "="*60)
    print("âš¡ ë¹„ë™ê¸° ì‘ì—…")
    print("="*60)

    import random
    embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

    try:
        # Store ìƒì„±
        store = VectorStore.chroma(
            collection_name="async_demo",
            embedding_function=embed_func
        )

        # ë¬¸ì„œ ì¶”ê°€ (ë™ê¸°)
        docs = [
            Document(content="Async document 1"),
            Document(content="Async document 2"),
            Document(content="Async document 3")
        ]
        store.add_documents(docs)
        print("\nâœ“ Documents added")

        # ë¹„ë™ê¸° ê²€ìƒ‰
        print("\në¹„ë™ê¸° ê²€ìƒ‰:")
        results = await store.asimilarity_search("async", k=2)
        print(f"   âœ“ Found {len(results)} results")

        print("\nâœ“ ë¹„ë™ê¸° ì‘ì—… ì™„ë£Œ!")

    except Exception as e:
        print(f"   âš ï¸  {e}")


def demo_provider_selection():
    """Provider ì„ íƒ"""
    print("\n" + "="*60)
    print("ğŸ” Provider ì„ íƒ")
    print("="*60)

    # ì‚¬ìš© ê°€ëŠ¥í•œ provider í™•ì¸
    print("\n1. ì‚¬ìš© ê°€ëŠ¥í•œ providers:")
    available = VectorStore.list_available_providers()
    print(f"   Available: {available}")

    # ê¸°ë³¸ provider
    default = VectorStore.get_default_provider()
    print(f"   Default: {default}")

    # ê° provider íŠ¹ì§•
    print("\n2. Provider íŠ¹ì§•:")
    print("   â€¢ Chroma: ë¡œì»¬, ì‚¬ìš©í•˜ê¸° ì‰¬ì›€, ë¹ ë¥¸ ì‹œì‘")
    print("   â€¢ FAISS: ë¡œì»¬, ë§¤ìš° ë¹ ë¦„, ëŒ€ìš©ëŸ‰ ë°ì´í„°")
    print("   â€¢ Pinecone: í´ë¼ìš°ë“œ, í™•ì¥ ê°€ëŠ¥, í”„ë¡œë•ì…˜")
    print("   â€¢ Qdrant: í´ë¼ìš°ë“œ/ë¡œì»¬, ëª¨ë˜, í•„í„°ë§ ê°•ë ¥")
    print("   â€¢ Weaviate: ì—”í„°í”„ë¼ì´ì¦ˆ, GraphQL, ë³µì¡í•œ ì¿¼ë¦¬")

    print("\nâœ“ Provider ì„ íƒ ì™„ë£Œ!")


def demo_comparison():
    """LangChain vs beanllm ë¹„êµ"""
    print("\n" + "="*60)
    print("ğŸ“Š LangChain vs beanllm ë¹„êµ")
    print("="*60)

    print("\nã€ LangChain ë°©ì‹ ã€‘")
    print("""
    from langchain.vectorstores import Chroma
    from langchain.embeddings import OpenAIEmbeddings

    # ì—¬ëŸ¬ import í•„ìš”
    embeddings = OpenAIEmbeddings()
    vectorstore = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        persist_directory="./db"
    )
    """)

    print("\nã€ beanllm ë°©ì‹ ã€‘")
    print("""
    from beanllm import from_documents, Embedding

    # ê°„ë‹¨í•˜ê³  ì§ê´€ì 
    embed_func = Embedding.openai().embed_sync
    store = from_documents(docs, embed_func, provider="chroma")
    """)

    print("\nâœ… beanllm: ë” ê°„ë‹¨í•˜ê³  ì§ê´€ì !")
    print("âœ… í†µí•© ì¸í„°í˜ì´ìŠ¤ë¡œ provider ì „í™˜ ì‰¬ì›€")
    print("âœ… Fluent APIë¡œ ê°€ë…ì„± í–¥ìƒ")


async def main():
    """ëª¨ë“  ë°ëª¨ ì‹¤í–‰"""
    print("="*60)
    print("ğŸ¯ Vector Stores ë°ëª¨")
    print("="*60)
    print("\nbeanllmì˜ ì² í•™:")
    print("  1. í†µí•© ì¸í„°í˜ì´ìŠ¤ (ëª¨ë“  vector store ë™ì¼í•œ API)")
    print("  2. Fluent API (Builder íŒ¨í„´)")
    print("  3. í¸ì˜ í•¨ìˆ˜ (from_documents)")
    print("  4. RAG íŒŒì´í”„ë¼ì¸ ì™„ì „ ì§€ì›")

    demo_basic_usage()
    demo_factory_methods()
    demo_fluent_api()
    demo_convenience_functions()
    await demo_full_rag_pipeline()
    await demo_async_operations()
    demo_provider_selection()
    demo_comparison()

    print("\n" + "="*60)
    print("ğŸ‰ Vector Stores ì™„ë£Œ!")
    print("="*60)
    print("\nâœ¨ ì£¼ìš” ê¸°ëŠ¥:")
    print("  1. VectorStore.chroma()  # íŒ©í† ë¦¬ ë©”ì„œë“œ")
    print("  2. from_documents(docs, embed_func)  # ê°€ì¥ í¸ë¦¬")
    print("  3. VectorStoreBuilder().use_chroma()  # Fluent API")
    print("  4. ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸")
    print("  5. 5ê°œ ì£¼ìš” provider ì§€ì›")
    print("\nğŸ’¡ Document â†’ Chunks â†’ Embeddings â†’ Vector Store â†’ Search!")


if __name__ == "__main__":
    asyncio.run(main())
