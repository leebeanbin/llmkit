"""
ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ ë°ëª¨
- Hybrid Search (ë²¡í„° + í‚¤ì›Œë“œ)
- Re-ranking (Cross-encoder)
- MMR Search (ë‹¤ì–‘ì„±)
- Embedding ê³ ê¸‰ ê¸°ëŠ¥
"""
from pathlib import Path
from beanllm import (
    DocumentLoader,
    TextSplitter,
    Embedding,
    from_documents,
    # Embedding ê³ ê¸‰ ê¸°ëŠ¥
    find_hard_negatives,
    mmr_search as embedding_mmr,
    query_expansion,
    EmbeddingCache
)


def demo_hybrid_search():
    """Hybrid Search - ë²¡í„° + í‚¤ì›Œë“œ"""
    print("\n" + "="*60)
    print("1ï¸âƒ£  Hybrid Search (ë²¡í„° + í‚¤ì›Œë“œ)")
    print("="*60)

    # í…ŒìŠ¤íŠ¸ íŒŒì¼
    test_file = Path("hybrid_test.txt")
    test_file.write_text("""
Python is a programming language used for web development.
JavaScript is essential for frontend development.
Machine learning requires Python and mathematics knowledge.
Deep learning uses neural networks for complex tasks.
Natural language processing helps computers understand text.
Computer vision enables image recognition and analysis.
    """.strip(), encoding="utf-8")

    try:
        import random
        embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

        # íŒŒì´í”„ë¼ì¸
        docs = DocumentLoader.load(test_file)
        chunks = TextSplitter.split(docs, chunk_size=100)
        store = from_documents(chunks, embed_func)

        # ì¼ë°˜ ë²¡í„° ê²€ìƒ‰
        print("\n[ë²¡í„° ê²€ìƒ‰ë§Œ]")
        results = store.similarity_search("programming", k=3)
        print(f"  ê²°ê³¼: {len(results)}ê°œ")
        for i, r in enumerate(results[:2], 1):
            print(f"  {i}. {r.document.content[:50]}...")

        # Hybrid Search
        print("\n[Hybrid Search (ë²¡í„° + í‚¤ì›Œë“œ)]")
        try:
            # alpha = 0.5 (ê· í˜•)
            results = store.hybrid_search("programming", k=3, alpha=0.5)
            print(f"  ê²°ê³¼: {len(results)}ê°œ")
            for i, r in enumerate(results[:2], 1):
                print(f"  {i}. Score: {r.score:.3f}")
                print(f"      {r.document.content[:50]}...")

            # alpha = 0.8 (ë²¡í„° ì¤‘ì‹¬)
            print("\n  alpha=0.8 (ë²¡í„° ì¤‘ì‹¬):")
            results = store.hybrid_search("programming", k=3, alpha=0.8)
            print(f"  ê²°ê³¼: {len(results)}ê°œ")

        except Exception as e:
            print(f"  âš ï¸  {e}")

        print("\nğŸ’¡ Hybrid SearchëŠ” ë²¡í„°ì™€ í‚¤ì›Œë“œë¥¼ ê²°í•©!")

    finally:
        if test_file.exists():
            test_file.unlink()


def demo_reranking():
    """Re-ranking - Cross-encoder"""
    print("\n" + "="*60)
    print("2ï¸âƒ£  Re-ranking (Cross-encoder)")
    print("="*60)

    # í…ŒìŠ¤íŠ¸ íŒŒì¼
    test_file = Path("rerank_test.txt")
    test_file.write_text("""
Artificial intelligence is transforming technology.
Machine learning algorithms learn from data patterns.
Deep learning uses neural networks with multiple layers.
Natural language processing understands human language.
Computer vision interprets visual information.
Robotics combines AI with mechanical engineering.
    """.strip(), encoding="utf-8")

    try:
        import random
        embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

        docs = DocumentLoader.load(test_file)
        chunks = TextSplitter.split(docs, chunk_size=100)
        store = from_documents(chunks, embed_func)

        # ì´ˆê¸° ê²€ìƒ‰ (ë” ë§ì´ ê°€ì ¸ì˜´)
        print("\n[ì´ˆê¸° ê²€ìƒ‰ - ìƒìœ„ 5ê°œ]")
        results = store.similarity_search("artificial intelligence", k=5)
        print(f"  ê²°ê³¼: {len(results)}ê°œ")
        for i, r in enumerate(results[:3], 1):
            print(f"  {i}. Score: {r.score:.3f}")
            print(f"      {r.document.content[:50]}...")

        # Re-ranking
        print("\n[Re-ranking í›„ - ìƒìœ„ 3ê°œ]")
        try:
            reranked = store.rerank(
                "artificial intelligence",
                results,
                top_k=3
            )
            print(f"  ê²°ê³¼: {len(reranked)}ê°œ")
            for i, r in enumerate(reranked, 1):
                print(f"  {i}. Score: {r.score:.3f}")
                print(f"      {r.document.content[:50]}...")

            print("\nğŸ’¡ Cross-encoderë¡œ ë” ì •í™•í•œ ìˆœìœ„!")

        except ImportError:
            print("  âš ï¸  sentence-transformers í•„ìš”:")
            print("     pip install sentence-transformers")

    finally:
        if test_file.exists():
            test_file.unlink()


def demo_mmr_search():
    """MMR Search - ë‹¤ì–‘ì„± ê³ ë ¤"""
    print("\n" + "="*60)
    print("3ï¸âƒ£  MMR Search (ë‹¤ì–‘ì„± ê³ ë ¤)")
    print("="*60)

    # í…ŒìŠ¤íŠ¸ íŒŒì¼ (ìœ ì‚¬í•œ ë‚´ìš©ë“¤)
    test_file = Path("mmr_test.txt")
    test_file.write_text("""
Python is great for machine learning.
Python is excellent for ML tasks.
Python is perfect for ML projects.
JavaScript is used for web development.
Java is popular for enterprise applications.
C++ is fast for system programming.
    """.strip(), encoding="utf-8")

    try:
        import random
        embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

        docs = DocumentLoader.load(test_file)
        chunks = TextSplitter.split(docs, chunk_size=100)
        store = from_documents(chunks, embed_func)

        # ì¼ë°˜ ê²€ìƒ‰ (ìœ ì‚¬í•œ ê²°ê³¼ë“¤)
        print("\n[ì¼ë°˜ ê²€ìƒ‰ - ìœ ì‚¬í•œ ê²°ê³¼ë“¤]")
        results = store.similarity_search("Python machine learning", k=4)
        print(f"  ê²°ê³¼: {len(results)}ê°œ")
        for i, r in enumerate(results, 1):
            print(f"  {i}. {r.document.content}")

        # MMR ê²€ìƒ‰ (ë‹¤ì–‘ì„± ê³ ë ¤)
        print("\n[MMR Search - ë‹¤ì–‘í•œ ê²°ê³¼]")
        results = store.mmr_search(
            "Python machine learning",
            k=4,
            fetch_k=6,
            lambda_param=0.5  # ê´€ë ¨ì„± 50%, ë‹¤ì–‘ì„± 50%
        )
        print(f"  ê²°ê³¼: {len(results)}ê°œ")
        for i, r in enumerate(results, 1):
            print(f"  {i}. {r.document.content}")

        print("\nğŸ’¡ MMRì€ ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ í”¼í•˜ê³  ë‹¤ì–‘ì„± í™•ë³´!")

    finally:
        if test_file.exists():
            test_file.unlink()


def demo_embedding_hard_negatives():
    """Embedding - Hard Negative Mining"""
    print("\n" + "="*60)
    print("4ï¸âƒ£  Hard Negative Mining")
    print("="*60)

    try:
        embed = Embedding.openai()

        # ì¿¼ë¦¬
        query = "ê³ ì–‘ì´ ì‚¬ë£Œ"

        # í›„ë³´ë“¤
        candidates_text = [
            "ê°•ì•„ì§€ ì‚¬ë£Œ",  # Hard negative (ë¹„ìŠ·í•˜ì§€ë§Œ ë‹¤ë¦„)
            "ê³ ì–‘ì´ ì¥ë‚œê°",  # Hard negative
            "ìë™ì°¨ ë¶€í’ˆ",  # Easy negative (ì™„ì „íˆ ë‹¤ë¦„)
            "ê³ ì–‘ì´ ê°„ì‹"   # Positive (ê´€ë ¨ìˆìŒ)
        ]

        print(f"\nì¿¼ë¦¬: '{query}'")
        print(f"í›„ë³´ {len(candidates_text)}ê°œ:")
        for i, text in enumerate(candidates_text, 1):
            print(f"  {i}. {text}")

        # ì„ë² ë”©
        query_vec = embed.embed_sync([query])[0]
        candidate_vecs = embed.embed_sync(candidates_text)

        # Hard Negatives ì°¾ê¸°
        hard_negs = find_hard_negatives(
            query_vec,
            candidate_vecs,
            threshold=0.7,  # ìœ ì‚¬ë„ 0.5~0.7 ì‚¬ì´
            top_k=2
        )

        print(f"\nHard Negatives ({len(hard_negs)}ê°œ):")
        for idx, score in hard_negs:
            print(f"  â€¢ {candidates_text[idx]} (ìœ ì‚¬ë„: {score:.3f})")

        print("\nğŸ’¡ Hard Negatives: ë¹„ìŠ·í•˜ì§€ë§Œ ë‹¤ë¥¸ ê²ƒë“¤ (í•™ìŠµì— ìœ ìš©)")

    except Exception as e:
        print(f"âš ï¸  {e}")


def demo_embedding_mmr():
    """Embedding - MMR for diversity"""
    print("\n" + "="*60)
    print("5ï¸âƒ£  MMR (Embedding ë ˆë²¨)")
    print("="*60)

    try:
        embed = Embedding.openai()

        # ì¿¼ë¦¬
        query = "í”„ë¡œê·¸ë˜ë° ì–¸ì–´"

        # í›„ë³´ë“¤ (ì¼ë¶€ ì¤‘ë³µ/ìœ ì‚¬)
        candidates_text = [
            "Pythonì€ ë°°ìš°ê¸° ì‰¬ìš´ ì–¸ì–´",
            "Pythonì€ ì¸ê¸°ìˆëŠ” ì–¸ì–´",
            "JavaScriptëŠ” ì›¹ ê°œë°œì— ì‚¬ìš©",
            "JavaëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰",
            "C++ëŠ” ì„±ëŠ¥ì´ ë›°ì–´ë‚¨",
            "RubyëŠ” ìƒì‚°ì„±ì´ ë†’ìŒ"
        ]

        print(f"\nì¿¼ë¦¬: '{query}'")
        print(f"í›„ë³´ {len(candidates_text)}ê°œ")

        # ì„ë² ë”©
        query_vec = embed.embed_sync([query])[0]
        candidate_vecs = embed.embed_sync(candidates_text)

        # MMRë¡œ ë‹¤ì–‘í•œ ê²°ê³¼ ì„ íƒ
        selected_indices = embedding_mmr(
            query_vec,
            candidate_vecs,
            k=3,
            lambda_param=0.6  # ê´€ë ¨ì„± 60%, ë‹¤ì–‘ì„± 40%
        )

        print(f"\nMMR ì„ íƒ ê²°ê³¼ ({len(selected_indices)}ê°œ):")
        for rank, idx in enumerate(selected_indices, 1):
            print(f"  {rank}. {candidates_text[idx]}")

        print("\nğŸ’¡ ì¤‘ë³µ/ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ í”¼í•˜ê³  ë‹¤ì–‘ì„± í™•ë³´!")

    except Exception as e:
        print(f"âš ï¸  {e}")


def demo_query_expansion():
    """Query Expansion"""
    print("\n" + "="*60)
    print("6ï¸âƒ£  Query Expansion")
    print("="*60)

    try:
        embed = Embedding.openai()

        # ì›ë³¸ ì¿¼ë¦¬
        query = "ê³ ì–‘ì´"

        # í™•ì¥ í›„ë³´
        expansion_candidates = [
            "ëƒ¥ì´", "ê³ ì–‘ì´ê³¼", "cat", "í˜ë¥´ì‹œì•ˆ", "ê¸¸ê³ ì–‘ì´",
            "ê°•ì•„ì§€", "í† ë¼", "í–„ìŠ¤í„°"  # ê´€ë ¨ì—†ëŠ” ê²ƒë“¤
        ]

        print(f"\nì›ë³¸ ì¿¼ë¦¬: '{query}'")
        print(f"í™•ì¥ í›„ë³´: {len(expansion_candidates)}ê°œ")

        # Query Expansion
        expanded = query_expansion(
            query,
            embed,
            expansion_candidates,
            top_k=3
        )

        print(f"\ní™•ì¥ëœ ì¿¼ë¦¬ ({len(expanded)}ê°œ):")
        for term, score in expanded:
            print(f"  â€¢ {term} (ìœ ì‚¬ë„: {score:.3f})")

        # í™•ì¥ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ê°€ëŠ¥
        expanded_query = " ".join([term for term, _ in expanded])
        print(f"\nìµœì¢… ì¿¼ë¦¬: '{query} {expanded_query}'")

        print("\nğŸ’¡ Query Expansionìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€!")

    except Exception as e:
        print(f"âš ï¸  {e}")


def demo_embedding_cache():
    """Embedding Cache"""
    print("\n" + "="*60)
    print("7ï¸âƒ£  Embedding Cache")
    print("="*60)

    try:
        from beanllm import EmbeddingCache
        import time

        embed = Embedding.openai()
        cache = EmbeddingCache(ttl=3600, max_size=1000)

        texts = ["Python programming", "Machine learning", "Deep learning"]

        # ì²« ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ miss)
        print("\n[ì²« ë²ˆì§¸ í˜¸ì¶œ - ìºì‹œ miss]")
        start = time.time()

        # ìºì‹œ í™•ì¸
        cached_vecs = []
        for text in texts:
            vec = cache.get(text)
            if vec:
                cached_vecs.append(vec)
            else:
                # ìºì‹œì— ì—†ìœ¼ë©´ ì„ë² ë”© ìƒì„±
                vec = embed.embed_sync([text])[0]
                cache.set(text, vec)
                cached_vecs.append(vec)

        elapsed1 = time.time() - start
        print(f"  ì‹œê°„: {elapsed1:.3f}ì´ˆ")
        print(f"  ìºì‹œ ìƒíƒœ: {cache.stats()}")

        # ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ hit)
        print("\n[ë‘ ë²ˆì§¸ í˜¸ì¶œ - ìºì‹œ hit]")
        start = time.time()

        cached_vecs = []
        for text in texts:
            vec = cache.get(text)
            if vec:
                cached_vecs.append(vec)

        elapsed2 = time.time() - start
        print(f"  ì‹œê°„: {elapsed2:.3f}ì´ˆ")
        print(f"  ìºì‹œ ìƒíƒœ: {cache.stats()}")

        speedup = elapsed1 / elapsed2 if elapsed2 > 0 else float('inf')
        print(f"\n  ì†ë„ í–¥ìƒ: {speedup:.1f}x")

        print("\nğŸ’¡ ìì£¼ ì‚¬ìš©í•˜ëŠ” ì„ë² ë”©ì€ ìºì‹œë¡œ ë¹ ë¥´ê²Œ!")

    except Exception as e:
        print(f"âš ï¸  {e}")


def main():
    """ëª¨ë“  ë°ëª¨ ì‹¤í–‰"""
    print("="*60)
    print("ğŸš€ ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ ë°ëª¨")
    print("="*60)
    print("\nVectorStore ê³ ê¸‰ ê²€ìƒ‰:")
    print("  1. Hybrid Search (ë²¡í„° + í‚¤ì›Œë“œ)")
    print("  2. Re-ranking (Cross-encoder)")
    print("  3. MMR Search (ë‹¤ì–‘ì„±)")
    print("\nEmbedding ê³ ê¸‰ ê¸°ëŠ¥:")
    print("  4. Hard Negative Mining")
    print("  5. MMR (Embedding)")
    print("  6. Query Expansion")
    print("  7. Embedding Cache")

    # VectorStore ê³ ê¸‰ ê²€ìƒ‰
    demo_hybrid_search()
    demo_reranking()
    demo_mmr_search()

    # Embedding ê³ ê¸‰ ê¸°ëŠ¥
    demo_embedding_hard_negatives()
    demo_embedding_mmr()
    demo_query_expansion()
    demo_embedding_cache()

    print("\n" + "="*60)
    print("ğŸ‰ ê³ ê¸‰ ê²€ìƒ‰ ë°ëª¨ ì™„ë£Œ!")
    print("="*60)
    print("\nâœ¨ í•µì‹¬ ê¸°ëŠ¥:")
    print("  VectorStore:")
    print("    â€¢ hybrid_search() - ë²¡í„° + í‚¤ì›Œë“œ")
    print("    â€¢ rerank() - Cross-encoder ì¬ìˆœìœ„í™”")
    print("    â€¢ mmr_search() - ë‹¤ì–‘ì„± ê³ ë ¤")
    print("\n  Embedding:")
    print("    â€¢ find_hard_negatives() - Hard Negative Mining")
    print("    â€¢ mmr_search() - MMR ì„ íƒ")
    print("    â€¢ query_expansion() - ì¿¼ë¦¬ í™•ì¥")
    print("    â€¢ EmbeddingCache - ìºì‹±")
    print("\nğŸ’¡ RAG í’ˆì§ˆì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ëŠ¥ë“¤!")


if __name__ == "__main__":
    main()
