"""
RAG Debugging Demo - RAG íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹…í•˜ê¸°
ì¤‘ê°„ ê³¼ì •ì„ í™•ì¸í•˜ê³  ë¬¸ì œë¥¼ ì°¾ëŠ” ë°©ë²•
"""
import asyncio
from pathlib import Path
from beanllm import (
    DocumentLoader,
    TextSplitter,
    Embedding,
    VectorStore,
    from_documents,
    # ë””ë²„ê¹… ë„êµ¬ë“¤
    RAGDebugger,
    inspect_embedding,
    compare_texts,
    validate_pipeline,
    visualize_embeddings_2d,
    similarity_heatmap
)


def demo_inspect_embedding():
    """ì„ë² ë”© ê²€ì‚¬"""
    print("\n" + "="*60)
    print("1ï¸âƒ£  ì„ë² ë”© ê²€ì‚¬")
    print("="*60)

    try:
        # ì„ë² ë”© í•¨ìˆ˜ ì¤€ë¹„
        embed_func = Embedding.openai().embed_sync

        # í…ìŠ¤íŠ¸ ì„ë² ë”©
        text = "Machine learning is a subset of artificial intelligence"

        # âœ… ë°©ë²• 1: ê°„ë‹¨í•œ í•¨ìˆ˜
        info = inspect_embedding(text, embed_func, show_preview=10)

        print(f"\nê²°ê³¼:")
        print(f"  ì°¨ì›: {info.dimension}")
        print(f"  ë²¡í„° í¬ê¸°: {info.norm:.4f}")
        print(f"  ë¯¸ë¦¬ë³´ê¸°: {info.preview[:5]}")

    except Exception as e:
        print(f"âš ï¸  OpenAI API í‚¤ í•„ìš”: {e}")
        print("   ë”ë¯¸ ì„ë² ë”©ìœ¼ë¡œ ëŒ€ì²´...")

        # ë”ë¯¸ ì„ë² ë”©
        import random
        embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]
        text = "Test text"
        info = inspect_embedding(text, embed_func, show_preview=5)


def demo_compare_texts():
    """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¹„êµ"""
    print("\n" + "="*60)
    print("2ï¸âƒ£  í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¹„êµ")
    print("="*60)

    try:
        embed_func = Embedding.openai().embed_sync

        # ìœ ì‚¬í•œ í…ìŠ¤íŠ¸
        print("\n[í…ŒìŠ¤íŠ¸ 1] ìœ ì‚¬í•œ í…ìŠ¤íŠ¸:")
        info1 = compare_texts("ê°•ì•„ì§€", "ê°œ", embed_func)
        print(f"  â†’ ìœ ì‚¬ë„: {info1.cosine_similarity:.3f} ({info1.interpretation})")

        # ë‹¤ë¥¸ í…ìŠ¤íŠ¸
        print("\n[í…ŒìŠ¤íŠ¸ 2] ë‹¤ë¥¸ í…ìŠ¤íŠ¸:")
        info2 = compare_texts("ê°•ì•„ì§€", "ìë™ì°¨", embed_func)
        print(f"  â†’ ìœ ì‚¬ë„: {info2.cosine_similarity:.3f} ({info2.interpretation})")

        # ê´€ë ¨ëœ í…ìŠ¤íŠ¸
        print("\n[í…ŒìŠ¤íŠ¸ 3] ê´€ë ¨ëœ í…ìŠ¤íŠ¸:")
        info3 = compare_texts(
            "Machine learning is amazing",
            "Deep learning is powerful",
            embed_func
        )
        print(f"  â†’ ìœ ì‚¬ë„: {info3.cosine_similarity:.3f} ({info3.interpretation})")

    except Exception as e:
        print(f"âš ï¸  {e}")


def demo_inspect_chunks():
    """ì²­í¬ ê²€ì‚¬"""
    print("\n" + "="*60)
    print("3ï¸âƒ£  ì²­í¬ ê²€ì‚¬")
    print("="*60)

    # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    test_file = Path("debug_test.txt")
    test_file.write_text("""
Artificial Intelligence is transforming technology.
Machine learning algorithms learn patterns from data.
Deep learning uses neural networks with multiple layers.
Natural language processing enables computers to understand text.
Computer vision allows machines to interpret images.
    """.strip(), encoding="utf-8")

    try:
        # ë¬¸ì„œ ë¡œë”© ë° ë¶„í• 
        docs = DocumentLoader.load(test_file)
        chunks = TextSplitter.split(docs, chunk_size=100)

        # ì²­í¬ ê²€ì‚¬
        debugger = RAGDebugger()
        stats = debugger.inspect_chunks(chunks, show_samples=3)

        print(f"\ní†µê³„:")
        print(f"  ì´ ì²­í¬: {stats['total_chunks']}")
        print(f"  í‰ê·  ê¸¸ì´: {stats['avg_length']:.1f}")

        # ì²­í¬ í¬ê¸° ë¶„í¬ í™•ì¸
        print(f"\nì²­í¬ í¬ê¸° ë¶„í¬:")
        for i, length in enumerate(stats['chunk_lengths'][:5], 1):
            print(f"  Chunk {i}: {length} ë¬¸ì")

    finally:
        if test_file.exists():
            test_file.unlink()


def demo_inspect_vector_store():
    """Vector Store ê²€ì‚¬"""
    print("\n" + "="*60)
    print("4ï¸âƒ£  Vector Store ê²€ì‚¬")
    print("="*60)

    # ë”ë¯¸ ì„ë² ë”© (API í‚¤ ì—†ì´ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥)
    import random
    embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

    try:
        # Vector Store ìƒì„± ë° ë¬¸ì„œ ì¶”ê°€
        from beanllm import Document

        docs = [
            Document(content="Python is a programming language"),
            Document(content="JavaScript is used for web development"),
            Document(content="Machine learning learns from data"),
            Document(content="Deep learning uses neural networks")
        ]

        store = from_documents(docs, embed_func, provider="chroma")

        # Vector Store ê²€ì‚¬
        debugger = RAGDebugger()
        results = debugger.inspect_vector_store(
            store,
            sample_queries=[
                "programming",
                "artificial intelligence",
                "web"
            ],
            k=2
        )

        print(f"\nê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:")
        for query, query_results in results.items():
            if query_results:
                print(f"  '{query}': {len(query_results)}ê°œ ê²°ê³¼")
            else:
                print(f"  '{query}': ê²°ê³¼ ì—†ìŒ")

    except Exception as e:
        print(f"âš ï¸  {e}")


def demo_validate_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦"""
    print("\n" + "="*60)
    print("5ï¸âƒ£  ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ê²€ì¦")
    print("="*60)

    # í…ŒìŠ¤íŠ¸ íŒŒì¼
    test_file = Path("pipeline_test.txt")
    test_file.write_text("""
Artificial Intelligence encompasses various technologies.
Machine learning is a subset of AI that learns from data.
Deep learning uses neural networks with multiple layers.
Natural language processing deals with text understanding.
Computer vision enables image and video analysis.
Reinforcement learning learns through trial and error.
    """.strip(), encoding="utf-8")

    try:
        # 1. ë¬¸ì„œ ë¡œë”©
        print("\nğŸ“„ ë¬¸ì„œ ë¡œë”©...")
        docs = DocumentLoader.load(test_file)
        print(f"   âœ“ {len(docs)}ê°œ ë¬¸ì„œ ë¡œë“œ")

        # 2. í…ìŠ¤íŠ¸ ë¶„í• 
        print("\nâœ‚ï¸  í…ìŠ¤íŠ¸ ë¶„í• ...")
        chunks = TextSplitter.split(docs, chunk_size=150)
        print(f"   âœ“ {len(chunks)}ê°œ ì²­í¬ ìƒì„±")

        # 3. ì„ë² ë”© ë° Vector Store
        print("\nğŸ”¢ ì„ë² ë”© ë° Vector Store...")
        import random
        embed_func = lambda texts: [[random.random() for _ in range(384)] for _ in texts]

        store = from_documents(chunks, embed_func, provider="chroma")
        print(f"   âœ“ Vector Store ìƒì„± ì™„ë£Œ")

        # 4. ì „ì²´ ê²€ì¦
        print("\nğŸ” ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦...")
        report = validate_pipeline(
            documents=docs,
            chunks=chunks,
            embedding_function=embed_func,
            store=store,
            test_queries=[
                "What is machine learning?",
                "Tell me about neural networks",
                "How does AI work?"
            ]
        )

        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š ê²€ì¦ ë³´ê³ ì„œ:")
        print(f"  ë¬¸ì„œ ìˆ˜: {report['documents']['count']}")
        print(f"  ì²­í¬ ìˆ˜: {report['chunks']['total_chunks']}")
        print(f"  ì„ë² ë”© ì°¨ì›: {report['embedding_dim']}")
        print(f"  ë°œê²¬ëœ ë¬¸ì œ: {len(report['issues'])}ê°œ")

        if report['issues']:
            print("\në¬¸ì œ ëª©ë¡:")
            for issue in report['issues']:
                print(f"  {issue}")

    except Exception as e:
        print(f"âš ï¸  {e}")
        import traceback
        traceback.print_exc()

    finally:
        if test_file.exists():
            test_file.unlink()


def demo_compare_multiple():
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë¹„êµ"""
    print("\n" + "="*60)
    print("6ï¸âƒ£  ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë¹„êµ (ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤)")
    print("="*60)

    try:
        embed_func = Embedding.openai().embed_sync

        # ì—¬ëŸ¬ í…ìŠ¤íŠ¸
        texts = [
            "ê°•ì•„ì§€",
            "ê°œ",
            "ê³ ì–‘ì´",
            "ìë™ì°¨",
            "ë¹„í–‰ê¸°"
        ]

        # ì„ë² ë”©
        print("\nì„ë² ë”© ìƒì„± ì¤‘...")
        vectors = embed_func(texts)

        # ë¹„êµ
        debugger = RAGDebugger()
        embeddings = list(zip(texts, vectors))
        debugger.compare_embeddings(embeddings)

    except Exception as e:
        print(f"âš ï¸  {e}")


def demo_visualization():
    """ì‹œê°í™” (ì„ íƒì )"""
    print("\n" + "="*60)
    print("7ï¸âƒ£  ì„ë² ë”© ì‹œê°í™” (ì„ íƒì )")
    print("="*60)

    try:
        # scikit-learn, matplotlib í™•ì¸
        import sklearn
        import matplotlib

        print("\nì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ë¨!")
        print("ì‹¤ì œ ì‹œê°í™”ë¥¼ ë³´ë ¤ë©´ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.\n")

        # ì£¼ì„ì„ í•´ì œí•˜ë©´ ì‹œê°í™” ì‹¤í–‰:
        # embed_func = Embedding.openai().embed_sync
        # texts = ["AI", "ML", "DL", "NLP", "CV", "ê°•ì•„ì§€", "ê³ ì–‘ì´", "ìë™ì°¨"]
        #
        # # 2D ì‹œê°í™”
        # visualize_embeddings_2d(texts, embed_func, save_path="embeddings_2d.png")
        #
        # # ìœ ì‚¬ë„ íˆíŠ¸ë§µ
        # similarity_heatmap(texts, embed_func, save_path="similarity_heatmap.png")

    except ImportError:
        print("\nâš ï¸  ì‹œê°í™”ë¥¼ ìœ„í•´ ì¶”ê°€ íŒ¨í‚¤ì§€ í•„ìš”:")
        print("   pip install scikit-learn matplotlib seaborn")


def demo_advanced_debugging():
    """ê³ ê¸‰ ë””ë²„ê¹…"""
    print("\n" + "="*60)
    print("8ï¸âƒ£  ê³ ê¸‰ ë””ë²„ê¹… - RAGDebugger í´ë˜ìŠ¤ ì§ì ‘ ì‚¬ìš©")
    print("="*60)

    # RAGDebugger ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    debugger = RAGDebugger(verbose=True)

    try:
        embed_func = Embedding.openai().embed_sync

        # 1. ì„ë² ë”© ê²€ì‚¬
        print("\n[1] ì„ë² ë”© ìƒì„¸ ê²€ì‚¬:")
        text = "The quick brown fox jumps over the lazy dog"
        vector = embed_func([text])[0]
        info = debugger.inspect_embedding(text, vector, show_preview=15)

        # 2. ìœ ì‚¬ë„ ë¶„ì„
        print("\n[2] ìœ ì‚¬ë„ ìƒì„¸ ë¶„ì„:")
        info = debugger.compare_texts(
            "artificial intelligence",
            "machine learning",
            embed_func
        )

        print(f"\në¶„ì„ ê²°ê³¼:")
        print(f"  ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {info.cosine_similarity:.4f}")
        print(f"  ìœ í´ë¦¬ë“œ ê±°ë¦¬: {info.euclidean_distance:.4f}")
        print(f"  í•´ì„: {info.interpretation}")

    except Exception as e:
        print(f"âš ï¸  {e}")


def main():
    """ëª¨ë“  ë°ëª¨ ì‹¤í–‰"""
    print("="*60)
    print("ğŸ” RAG ë””ë²„ê¹… ë„êµ¬ ë°ëª¨")
    print("="*60)
    print("\nRAG íŒŒì´í”„ë¼ì¸ ê°œë°œ ì‹œ ìœ ìš©í•œ ë””ë²„ê¹… ë„êµ¬ë“¤ì„ ì†Œê°œí•©ë‹ˆë‹¤.")
    print("ê° ë‹¨ê³„ì—ì„œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n")

    demo_inspect_embedding()
    demo_compare_texts()
    demo_inspect_chunks()
    demo_inspect_vector_store()
    demo_validate_pipeline()
    demo_compare_multiple()
    demo_visualization()
    demo_advanced_debugging()

    print("\n" + "="*60)
    print("ğŸ‰ RAG ë””ë²„ê¹… ë°ëª¨ ì™„ë£Œ!")
    print("="*60)
    print("\nâœ¨ ì£¼ìš” ê¸°ëŠ¥:")
    print("  1. inspect_embedding() - ì„ë² ë”© ê²€ì‚¬")
    print("  2. compare_texts() - í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¹„êµ")
    print("  3. validate_pipeline() - ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦")
    print("  4. visualize_embeddings_2d() - 2D ì‹œê°í™”")
    print("  5. similarity_heatmap() - ìœ ì‚¬ë„ íˆíŠ¸ë§µ")
    print("\nğŸ’¡ ì´ì œ RAG íŒŒì´í”„ë¼ì¸ ê°œë°œì´ í›¨ì”¬ ì‰¬ì›Œì§‘ë‹ˆë‹¤!")


if __name__ == "__main__":
    main()
