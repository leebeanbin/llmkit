"""
RAG Demo - Document Loading & Text Splitting
beanllm ë°©ì‹: ìë™ ê°ì§€ + ìŠ¤ë§ˆíŠ¸ ê¸°ë³¸ê°’
"""
import asyncio
from pathlib import Path


def demo_document_loading():
    """Document Loading ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ“„ Document Loading Demo")
    print("="*60)

    from beanllm import DocumentLoader, load_documents

    # 1. í…ìŠ¤íŠ¸ íŒŒì¼ (ìë™ ê°ì§€!)
    print("\n1. Auto-detect Text File:")
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    test_file = Path("test_doc.txt")
    test_file.write_text("This is a test document.\nWith multiple lines.\nFor testing beanllm!", encoding="utf-8")

    docs = DocumentLoader.load(test_file)
    print(f"   Loaded {len(docs)} document(s)")
    print(f"   Content: {docs[0].content[:50]}...")
    print(f"   Metadata: {docs[0].metadata}")

    # í¸ì˜ í•¨ìˆ˜
    docs2 = load_documents(test_file)
    print(f"   âœ“ Same result with convenience function: {len(docs2)} doc(s)")

    # ì •ë¦¬
    test_file.unlink()

    # 2. CSV íŒŒì¼ (ìë™ ê°ì§€!)
    print("\n2. Auto-detect CSV File:")
    csv_file = Path("test_data.csv")
    csv_file.write_text("name,age,city\nAlice,30,Seoul\nBob,25,Busan\nCharlie,35,Incheon", encoding="utf-8")

    docs = DocumentLoader.load(csv_file)
    print(f"   Loaded {len(docs)} document(s) (one per row)")
    print(f"   First row: {docs[0].content[:50]}...")

    # íŠ¹ì • ì»¬ëŸ¼ë§Œ
    docs_custom = DocumentLoader.load(csv_file, content_columns=["name", "city"])
    print(f"   Custom columns: {docs_custom[0].content}")

    # ì •ë¦¬
    csv_file.unlink()

    print("\nâœ“ Document Loading: AUTO-DETECTION works!")


def demo_text_splitting():
    """Text Splitting ë°ëª¨"""
    print("\n" + "="*60)
    print("âœ‚ï¸  Text Splitting Demo")
    print("="*60)

    from beanllm import DocumentLoader, TextSplitter, split_documents, Document

    # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    long_text = """
# Introduction to AI

Artificial Intelligence (AI) is transforming the world. It enables machines to learn from experience.

## Machine Learning

Machine Learning is a subset of AI. It focuses on algorithms that improve through experience.

### Supervised Learning

In supervised learning, we train models on labeled data. The model learns to predict outcomes.

### Unsupervised Learning

Unsupervised learning works with unlabeled data. It finds patterns without explicit guidance.

## Deep Learning

Deep Learning uses neural networks with multiple layers. It powers modern AI applications like image recognition and natural language processing.

# Conclusion

AI continues to evolve rapidly. The future holds exciting possibilities.
    """.strip()

    docs = [Document(content=long_text, metadata={"source": "ai_intro.md"})]

    # 1. ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• (ìŠ¤ë§ˆíŠ¸ ê¸°ë³¸ê°’!)
    print("\n1. Simplest Way (Smart Defaults):")
    chunks = TextSplitter.split(docs, chunk_size=200)
    print(f"   Split into {len(chunks)} chunks")
    print(f"   First chunk: {chunks[0].content[:80]}...")
    print(f"   Metadata preserved: {chunks[0].metadata}")

    # 2. í¸ì˜ í•¨ìˆ˜
    print("\n2. Convenience Function:")
    chunks2 = split_documents(docs, chunk_size=200)
    print(f"   Same result: {len(chunks2)} chunks")

    # 3. ë‹¤ì–‘í•œ ì „ëµ
    print("\n3. Different Strategies:")

    # Recursive (ê¸°ë³¸, ê°€ì¥ ê¶Œì¥)
    chunks_recursive = TextSplitter.split(
        docs,
        strategy="recursive",
        chunk_size=200,
        chunk_overlap=50
    )
    print(f"   Recursive: {len(chunks_recursive)} chunks (recommended)")

    # Character
    chunks_char = TextSplitter.split(
        docs,
        strategy="character",
        separator="\n\n",
        chunk_size=200
    )
    print(f"   Character: {len(chunks_char)} chunks")

    # 4. ë§ˆí¬ë‹¤ìš´ í—¤ë” ë¶„í• 
    print("\n4. Markdown Header Splitting:")
    from beanllm import MarkdownHeaderTextSplitter

    md_splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=[
            ("#", "Header1"),
            ("##", "Header2"),
            ("###", "Header3"),
        ]
    )
    md_chunks = md_splitter.split_documents(docs)
    print(f"   Split by headers: {len(md_chunks)} chunks")
    for i, chunk in enumerate(md_chunks[:3]):
        print(f"   Chunk {i+1} metadata: {chunk.metadata}")

    print("\nâœ“ Text Splitting: SMART DEFAULTS work!")


def demo_token_splitting():
    """Token-based Splitting ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸ”¢ Token-based Splitting Demo")
    print("="*60)

    try:
        import tiktoken
    except ImportError:
        print("\nâš ï¸  tiktoken not installed. Install with: pip install tiktoken")
        return

    from beanllm import TextSplitter, Document

    text = "AI is amazing. " * 100  # ê¸´ í…ìŠ¤íŠ¸
    docs = [Document(content=text, metadata={"source": "test"})]

    # Token ê¸°ë°˜ ë¶„í• 
    print("\n1. Token-based Splitting (for LLM context limits):")
    chunks = TextSplitter.split(
        docs,
        strategy="token",
        chunk_size=50,  # í† í° ë‹¨ìœ„
        chunk_overlap=10
    )
    print(f"   Split into {len(chunks)} chunks (50 tokens each)")
    print(f"   First chunk: {chunks[0].content[:50]}...")

    # íŠ¹ì • ëª¨ë¸ìš©
    print("\n2. Model-specific (GPT-4):")
    from beanllm import TokenTextSplitter

    splitter = TokenTextSplitter(
        model_name="gpt-4",
        chunk_size=100,
        chunk_overlap=20
    )
    chunks2 = splitter.split_documents(docs)
    print(f"   Split for GPT-4: {len(chunks2)} chunks")

    print("\nâœ“ Token Splitting: Works great for LLM context management!")


def demo_full_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë°ëª¨"""
    print("\n" + "="*60)
    print("ğŸš€ Full RAG Pipeline Demo")
    print("="*60)

    from beanllm import DocumentLoader, TextSplitter

    # 1. ë¬¸ì„œ ë¡œë”© (ìë™ ê°ì§€)
    print("\n1. Load Documents (Auto-detect):")
    test_file = Path("rag_test.txt")
    test_file.write_text("""
AI and Machine Learning

Artificial Intelligence is revolutionizing technology. Machine learning algorithms learn from data.

Deep Learning

Deep learning uses neural networks. These networks have multiple layers that process information hierarchically.

Applications

AI powers many applications: voice assistants, image recognition, autonomous vehicles, and more.

Future of AI

The future of AI is bright. New breakthroughs happen constantly.
    """.strip(), encoding="utf-8")

    docs = DocumentLoader.load(test_file)
    print(f"   âœ“ Loaded: {len(docs)} document(s)")
    print(f"   Content length: {len(docs[0].content)} characters")

    # 2. í…ìŠ¤íŠ¸ ë¶„í•  (ìŠ¤ë§ˆíŠ¸ ê¸°ë³¸ê°’)
    print("\n2. Split Text (Smart defaults):")
    chunks = TextSplitter.split(docs, chunk_size=150, chunk_overlap=30)
    print(f"   âœ“ Split into: {len(chunks)} chunks")

    # ê° ì²­í¬ ë¯¸ë¦¬ë³´ê¸°
    print("\n   Chunks preview:")
    for i, chunk in enumerate(chunks[:3]):
        print(f"   Chunk {i+1}: {chunk.content[:60]}...")
        print(f"            Metadata: chunk={chunk.metadata.get('chunk', 'N/A')}")

    # ì •ë¦¬
    test_file.unlink()

    print("\n" + "="*60)
    print("ğŸ‰ beanllm RAG: Simple & Pythonic!")
    print("="*60)
    print("\nKey Features:")
    print("  âœ… Auto-detection (no manual loader selection)")
    print("  âœ… Smart defaults (optimal settings out of the box)")
    print("  âœ… One-line usage for 80% of cases")
    print("  âœ… Full customization for 20% of cases")
    print("  âœ… Pythonic and intuitive API")
    print("\nNext: Embeddings & Vector Stores!")


def main():
    """Run all demos"""
    demo_document_loading()
    demo_text_splitting()
    demo_token_splitting()
    demo_full_pipeline()


if __name__ == "__main__":
    main()
