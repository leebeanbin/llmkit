"""
Model Parameters Example
ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° ì •ë³´ í™•ì¸
"""

from beanllm import get_registry

def main():
    print("=== Model Parameters Check ===\n")

    registry = get_registry()

    # Check different model types
    models_to_check = [
        "gpt-4o",           # Standard OpenAI
        "gpt-5-mini",       # New OpenAI (max_completion_tokens)
        "gpt-5-nano",       # New OpenAI (no temperature)
        "claude-3-5-sonnet-20241022",  # Claude
        "gemini-2.5-flash", # Gemini
        "phi3.5",           # Ollama
    ]

    for model_name in models_to_check:
        model_info = registry.get_model_info(model_name)

        if not model_info:
            print(f"âŒ {model_name}: Not found")
            print()
            continue

        print(f"ğŸ“¦ {model_name}")
        print(f"   Provider: {model_info.provider}")
        print(f"   Type: {model_info.model_type}")
        print(f"\n   Capabilities:")
        print(f"     Streaming: {'âœ…' if model_info.supports_streaming else 'âŒ'}")
        print(f"     Temperature: {'âœ…' if model_info.supports_temperature else 'âŒ'}")

        if model_info.supports_temperature:
            print(f"       Range: {model_info.default_temperature}")

        print(f"     Max Tokens: {'âœ…' if model_info.supports_max_tokens else 'âŒ'}")

        if model_info.uses_max_completion_tokens:
            print(f"     âš ï¸ Uses 'max_completion_tokens' instead of 'max_tokens'")

        print(f"     Max Value: {model_info.max_tokens}")

        print(f"\n   Parameters:")
        for param in model_info.parameters:
            status = 'âœ…' if param.supported else 'âŒ'
            print(f"     {status} {param.name} ({param.type})")
            if param.notes:
                print(f"        Note: {param.notes}")

        print()

if __name__ == "__main__":
    main()
